{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfc6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01b49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c0df6",
   "metadata": {},
   "source": [
    "### 2.2 Tokenizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91421bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the-verdict.txt', <http.client.HTTPMessage at 0x28e92ceaaf0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare text\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    " \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    " \"the-verdict.txt\")\n",
    "file_path = \"the-verdict.txt\"\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91446fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  20479\n",
      "content part:  I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# look content\n",
    "with open(\"the-verdict.txt\", \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"length: \", len(raw_text))\n",
    "print(\"content part: \", raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d064d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "text_split = re.split(\"(\\s)\", text)\n",
    "print(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da0512d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "# 区分标点\n",
    "text_split1 = re.split(\"([.,]|\\s)\", text)\n",
    "print(text_split1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e06724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "# 去除空格\n",
    "text_split2 = [item for item in text_split1 if item.strip()]\n",
    "print(text_split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b27383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'Is', ' ', 'this', '--', '', ' ', 'a', ' ', 'test', '?', '']\n"
     ]
    }
   ],
   "source": [
    "# 增加token种类\n",
    "text = \"Hello, world. Is this-- a test?\"\n",
    "text_split3 = re.split(\"([,.?]|--|\\s)\", text)\n",
    "print(text_split3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d09a8c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text_split4 = [item for item in text_split3 if item.strip()]\n",
    "print(text_split4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dcac4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整个文本\n",
    "raw_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d4bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split5 = re.split(r'([,.?\"\\';:_!()]|--|\\s)', raw_text)\n",
    "text_split5 = [item for item in text_split5 if item.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ad874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--']\n"
     ]
    }
   ],
   "source": [
    "print(text_split5[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1e3816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(text_split5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98432d81",
   "metadata": {},
   "source": [
    "### 2.3 Converting tokens into token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c92824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(text_split5))\n",
    "len_words = len(all_words)\n",
    "print(len_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1331ba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e66c0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对token生成id\n",
    "vocab = {token:token_id for token_id, token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c2c3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b21aa7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for item in vocab.items():\n",
    "    if count > 50:\n",
    "        break\n",
    "    print(item)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "574f84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['For']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852605bb",
   "metadata": {},
   "source": [
    "tokenizer类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d4d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_id = vocab\n",
    "        self.id_to_str = {i:s for s, i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        processed = re.split(r'([,.?\"\\';:_!()]|--|\\s)', text)  # 将传入的文本分词\n",
    "        processed_new = [item.strip() for item in processed if item.strip()]  # 去除空格\n",
    "        ids = [self.str_to_id[item] for item in processed_new]  # 将字符变为token_id\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join(self.id_to_str[i] for i in ids)  # 拼接所有字符\n",
    "        text_new = re.sub(r'\\s+([,.?\"\\';:_!()])', r'\\1', text)  # 去除符号前空格\n",
    "        return text_new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c0fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "# 查看编码效果\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    " Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "378c3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "# 查看解码效果\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18d6f13e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24312\\1763555282.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Hello, do you like tea?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24312\\471055005.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'([,.?\"\\';:_!()]|--|\\s)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 将传入的文本分词\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprocessed_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 去除空格\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed_new\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 将字符变为token_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24312\\471055005.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'([,.?\"\\';:_!()]|--|\\s)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 将传入的文本分词\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprocessed_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 去除空格\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed_new\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 将字符变为token_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "text = \"Hello, do you like tea?\"\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3101b7",
   "metadata": {},
   "source": [
    "**Hello**无法被识别因为之前的词表里没有"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810a48f",
   "metadata": {},
   "source": [
    "### 2.4 Adding special context tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2c99b",
   "metadata": {},
   "source": [
    "加入\"<|unk|>\"和\"<|endoftext|>\"表示未知字符和文本结尾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47b1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(set(text_split5))\n",
    "all_tokens.extend(['<|unk|>', '<|endoftext|>'])\n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54328a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_new = {item:token_id for token_id, item in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "029a94fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|unk|>', 1130)\n",
      "('<|endoftext|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in list(vocab_new.items())[-5:]:\n",
    "#     if count > 50:\n",
    "#         break\n",
    "    print(i)\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edbe8c",
   "metadata": {},
   "source": [
    "建立新版tokenizer类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c0835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_id = vocab\n",
    "        self.id_to_str = {i:s for s, i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        processed = re.split(r'([,.?\"\\';:_!()]|--|\\s)', text)\n",
    "        processed_new = [item.strip() for item in processed if item.strip()]\n",
    "        processed_with_spec_char = [item if item in self.str_to_id else '<|unk|>' for item in processed_new]  # 将不在词表中的字符设为未知字符\n",
    "        ids = [self.str_to_id[item] for item in processed_with_spec_char]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.id_to_str[i] for i in ids])\n",
    "        text_new = re.sub(r'\\s+([,.?\"\\';:_!()])', r\"\\1\", text)\n",
    "        return text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a699dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5187b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130, 5, 355, 1126, 628, 975, 10, 1131, 55, 988, 956, 984, 722, 988, 1130, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer2 = SimpleTokenizerV2(vocab_new)\n",
    "ids2 = tokenizer2.encode(text)\n",
    "print(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "824c5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer2.decode(ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02c6737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"2020 Missouri Amendment 2, also called the Medicaid Expansion Initiative, was a ballot measure to amend the Constitution of Missouri to expand Medicaid under the Affordable Care Act. The initiative was on the August 4, 2020, primary ballot and passed with 53.27% of the vote. Following Medicaid expansion initiatives in other states, Republican lawmakers in Nebraska and Utah added work requirements to their states' expansions; supporters aimed to prevent this by proposing state constitutional amendments for future Medicaid expansion initiatives. The measure was supported most in urban areas and opposed in rural areas. After a delay due to a lack of funding from the Missouri General Assembly and resulting litigation, the initiative was slowly implemented in October 2021. Republican lawmakers attempted to roll back the program and add a work requirement through a state constitutional amendment, which failed after the United States Supreme Court prevented its implementation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "950cf7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130, 1130, 1130, 1130, 5, 1130, 242, 988, 1130, 1130, 1130, 5, 1077, 115, 1130, 1130, 1016, 1130, 988, 1130, 722, 1130, 1016, 1130, 1130, 1044, 988, 1130, 1130, 1130, 7, 93, 1130, 1077, 727, 988, 1130, 1130, 5, 1130, 5, 1130, 1130, 157, 1130, 1108, 1130, 7, 1130, 722, 988, 1130, 7, 1130, 1130, 1130, 1130, 568, 735, 1130, 5, 1130, 1130, 568, 1130, 157, 1130, 130, 1117, 1130, 1016, 989, 1130, 2, 1130, 9, 1130, 1130, 1016, 1130, 999, 241, 1130, 1130, 1130, 1130, 456, 1130, 1130, 1130, 1130, 7, 93, 1130, 1077, 1130, 686, 568, 1130, 1130, 157, 1130, 568, 1130, 1130, 7, 1130, 115, 1130, 1130, 1016, 115, 1130, 722, 1130, 477, 988, 1130, 1130, 1130, 157, 1130, 1130, 5, 988, 1130, 1077, 903, 1130, 568, 1130, 1130, 7, 1130, 1130, 1130, 1016, 1130, 191, 988, 1130, 157, 129, 115, 1117, 1130, 1007, 115, 1130, 1130, 1130, 5, 1093, 422, 138, 988, 1130, 1130, 1130, 1130, 1130, 586, 1130, 7]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer2.encode(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "119b2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_try = tokenizer2.encode(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec2bd6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|> <|unk|> <|unk|> <|unk|>, <|unk|> called the <|unk|> <|unk|> <|unk|>, was a <|unk|> <|unk|> to <|unk|> the <|unk|> of <|unk|> to <|unk|> <|unk|> under the <|unk|> <|unk|> <|unk|>. The <|unk|> was on the <|unk|> <|unk|>, <|unk|>, <|unk|> <|unk|> and <|unk|> with <|unk|>. <|unk|> of the <|unk|>. <|unk|> <|unk|> <|unk|> <|unk|> in other <|unk|>, <|unk|> <|unk|> in <|unk|> and <|unk|> added work <|unk|> to their <|unk|>' <|unk|>; <|unk|> <|unk|> to <|unk|> this by <|unk|> <|unk|> <|unk|> <|unk|> for <|unk|> <|unk|> <|unk|> <|unk|>. The <|unk|> was <|unk|> most in <|unk|> <|unk|> and <|unk|> in <|unk|> <|unk|>. <|unk|> a <|unk|> <|unk|> to a <|unk|> of <|unk|> from the <|unk|> <|unk|> <|unk|> and <|unk|> <|unk|>, the <|unk|> was slowly <|unk|> in <|unk|> <|unk|>. <|unk|> <|unk|> <|unk|> to <|unk|> back the <|unk|> and add a work <|unk|> through a <|unk|> <|unk|> <|unk|>, which failed after the <|unk|> <|unk|> <|unk|> <|unk|> <|unk|> its <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer2.decode(ids_try))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19ba73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce9d048b",
   "metadata": {},
   "source": [
    "### 2.5 Byte pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f7d0fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp39-cp39-win_amd64.whl (894 kB)\n",
      "     -------------------------------------- 894.2/894.2 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\anaconda\\anaconda1\\lib\\site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anaconda\\anaconda1\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\anaconda1\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\anaconda1\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\anaconda1\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\anaconda1\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.11)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f405a617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a8ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bpe = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccd29619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9906, 11, 656, 499, 1093, 15600, 30, 220, 100257, 763, 279, 7160, 32735, 7317, 2492, 315, 1063, 16476, 17826, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    " \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    " \" of someunknownPlace.\"\n",
    ")\n",
    "ids = tokenizer_bpe.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89ac1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_bpe.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7f2f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2366, 15, 25378, 22454, 220, 17, 11, 1101, 2663, 279, 34129, 55654, 38756, 11, 574, 264, 26938, 6767, 311, 30569, 279, 18039, 315, 25378, 311, 9407, 34129, 1234, 279, 43606, 10852, 3298, 13, 578, 20770, 574, 389, 279, 6287, 220, 19, 11, 220, 2366, 15, 11, 6156, 26938, 323, 5946, 449, 220, 4331, 13, 1544, 4, 315, 279, 7055, 13, 23548, 34129, 14800, 28271, 304, 1023, 5415, 11, 9540, 26137, 304, 38379, 323, 23195, 3779, 990, 8670, 311, 872, 5415, 6, 78588, 26, 15879, 20034, 311, 5471, 420, 555, 57515, 1614, 25543, 41693, 369, 3938, 34129, 14800, 28271, 13, 578, 6767, 574, 7396, 1455, 304, 16036, 5789, 323, 16475, 304, 19624, 5789, 13, 4740, 264, 7781, 4245, 311, 264, 6996, 315, 11006, 505, 279, 25378, 3331, 12000, 323, 13239, 39725, 11, 279, 20770, 574, 14297, 11798, 304, 6664, 220, 2366, 16, 13, 9540, 26137, 17644, 311, 6638, 1203, 279, 2068, 323, 923, 264, 990, 16686, 1555, 264, 1614, 25543, 28238, 11, 902, 4745, 1306, 279, 3723, 4273, 13814, 7301, 32098, 1202, 8292, 13]\n"
     ]
    }
   ],
   "source": [
    "ids1 = tokenizer_bpe.encode(text1)\n",
    "print(ids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c37e4098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 Missouri Amendment 2, also called the Medicaid Expansion Initiative, was a ballot measure to amend the Constitution of Missouri to expand Medicaid under the Affordable Care Act. The initiative was on the August 4, 2020, primary ballot and passed with 53.27% of the vote. Following Medicaid expansion initiatives in other states, Republican lawmakers in Nebraska and Utah added work requirements to their states' expansions; supporters aimed to prevent this by proposing state constitutional amendments for future Medicaid expansion initiatives. The measure was supported most in urban areas and opposed in rural areas. After a delay due to a lack of funding from the Missouri General Assembly and resulting litigation, the initiative was slowly implemented in October 2021. Republican lawmakers attempted to roll back the program and add a work requirement through a state constitutional amendment, which failed after the United States Supreme Court prevented its implementation.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_bpe.decode(ids1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fb234a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_wiki = \"\"\"After the 30 September Movement, many members of the Indonesian Communist Party (PKI), as well as several ABRI personnel from East Java, fled to Mbah Suro's hermitage in Nginggil to avoid being arrested by the government.[1] Mbah Suro's followers continued to grow in number. In 1966, the Blora Attorney estimated that the number of Mbah Suro's followers had reached 500,000 people.[2]\n",
    "\n",
    "Mbah Suro often gave speeches to his followers about the prophecy of the coming of the ratu adil (just king) and instructed them to chant slogans such as “Long live Mbah Suro” and “Long live Sukarno.” His speeches led the New Order authorities to begin monitoring his activities starting in 1966.[3] To prepare for an attack from the New Order government, Mbah Suro formed a hermitage armed forces consisting of two battalions: Banteng Wulung and Banteng Sarinah. Banteng Wulung had 200 personnel, while Banteng Sarinah was composed of 35 women.[4]\n",
    "\n",
    "The Commander of the IV Military Regional Command/Diponegoro (Kodam Diponegoro) had requested Mbah Suro to shut down his hermitage and also sent an envoy, Srinardi, to persuade him. The government made this effort four times. However, Mbah Suro rejected the request, and his followers assaulted the envoy from the Kodam Diponegoro.[5][6][7]\n",
    "\n",
    "In November 1966, the ABRI team for Operation Kalong successfully arrested an Islamic studies lecturer in Jakarta, Djaelani, who was attempting to gather remaining BTI cadres in Jakarta to launch a rebellion against the \"feudal class.\" In his statement, he revealed that he had been instructed by a shadow PKI member from Ngawi named Ngabdu, who was living in Mbah Suro's hermitage, to gather the BTI cadres. From Djaelani's confession, it was uncovered that Mbah Suro's hermitage was harboring PKI members. Based on his testimony—along with Mbah Suro's refusal to comply with the orders of the Diponegoro Division Commander—ABRI began planning an attack on Nginggil, which they codenamed Operation Kamtib.[5][8][9]\n",
    "\n",
    "In planning Operation Kamtib in Nginggil, ABRI deployed troops from Battalions 408, 409, and 410, as well as RPKAD special forces. In addition, ABRI also mobilized support troops from Military Regional Command/Brawijaya which were the Military Area Command 0805/Ngawi and District Military Area Command 0813/Bojonegoro. The operation was led by Commander of District Military Command 0721, Major Srinardi. Meanwhile, Feisal Tanjung led the RPKAD forces.[10][1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3193c5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_wiki' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7700\\1743329240.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mids_wiki\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer_bpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_wiki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_wiki\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_wiki' is not defined"
     ]
    }
   ],
   "source": [
    "ids_wiki = tokenizer_bpe.encode(text_wiki)\n",
    "print(ids_wiki[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c2eec359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the 30 September Movement, many members of the Indonesian Communist Party (PKI), as well as several ABRI personnel from East Java, fled to Mbah Suro's hermitage in Nginggil to avoid being arrested by the government.[1] Mbah Suro's followers continued to grow in number. In 1966, the Blora Attorney estimated that the number of Mbah Suro's followers had reached 500,000 people.[2]\n",
      "\n",
      "Mbah Suro often gave speeches to his followers about the prophecy of the coming of the ratu adil (just king) and instructed them to chant slogans such as “Long live Mbah Suro” and “Long live Sukarno.” His speeches led the New Order authorities to begin monitoring his activities starting in 1966.[3] To prepare for an attack from the New Order government, Mbah Suro formed a hermitage armed forces consisting of two battalions: Banteng Wulung and Banteng Sarinah. Banteng Wulung had 200 personnel, while Banteng Sarinah was composed of 35 women.[4]\n",
      "\n",
      "The Commander of the IV Military Regional Command/Diponegoro (Kodam Diponegoro) had requested Mbah Suro to shut down his hermitage and also sent an envoy, Srinardi, to persuade him. The government made this effort four times. However, Mbah Suro rejected the request, and his followers assaulted the envoy from the Kodam Diponegoro.[5][6][7]\n",
      "\n",
      "In November 1966, the ABRI team for Operation Kalong successfully arrested an Islamic studies lecturer in Jakarta, Djaelani, who was attempting to gather remaining BTI cadres in Jakarta to launch a rebellion against the \"feudal class.\" In his statement, he revealed that he had been instructed by a shadow PKI member from Ngawi named Ngabdu, who was living in Mbah Suro's hermitage, to gather the BTI cadres. From Djaelani's confession, it was uncovered that Mbah Suro's hermitage was harboring PKI members. Based on his testimony—along with Mbah Suro's refusal to comply with the orders of the Diponegoro Division Commander—ABRI began planning an attack on Nginggil, which they codenamed Operation Kamtib.[5][8][9]\n",
      "\n",
      "In planning Operation Kamtib in Nginggil, ABRI deployed troops from Battalions 408, 409, and 410, as well as RPKAD special forces. In addition, ABRI also mobilized support troops from Military Regional Command/Brawijaya which were the Military Area Command 0805/Ngawi and District Military Area Command 0813/Bojonegoro. The operation was led by Commander of District Military Command 0721, Major Srinardi. Meanwhile, Feisal Tanjung led the RPKAD forces.[10][1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_bpe.decode(ids_wiki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86896637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c81fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea399fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "765c0cdf",
   "metadata": {},
   "source": [
    "### 2.6 Data sampling with a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be2c4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba221c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap g'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6808e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4943\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer_bpe.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f71a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6e2827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[40, 473, 1846, 2744]\n",
      "y:    [473, 1846, 2744, 3463]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size + 1]\n",
    "print(f\"x:{x}\")\n",
    "print(f\"y:    {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8cbbab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aff78660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] ----> 473\n",
      "[40, 473] ----> 1846\n",
      "[40, 473, 1846] ----> 2744\n",
      "[40, 473, 1846, 2744] ----> 3463\n",
      "[40, 473, 1846, 2744, 3463] ----> 7762\n",
      "[40, 473, 1846, 2744, 3463, 7762] ----> 480\n",
      "[40, 473, 1846, 2744, 3463, 7762, 480] ----> 285\n",
      "[40, 473, 1846, 2744, 3463, 7762, 480, 285] ----> 22464\n",
      "[40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464] ----> 4856\n",
      "[40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856] ----> 264\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    content = enc_sample[:i]\n",
    "    desire = enc_sample[i]\n",
    "    print(content, \"---->\", desire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3faf07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---->  H\n",
      "I H ----> AD\n",
      "I HAD ---->  always\n",
      "I HAD always ---->  thought\n",
      "I HAD always thought ---->  Jack\n",
      "I HAD always thought Jack ---->  G\n",
      "I HAD always thought Jack G ----> is\n",
      "I HAD always thought Jack Gis ----> burn\n",
      "I HAD always thought Jack Gisburn ---->  rather\n",
      "I HAD always thought Jack Gisburn rather ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    content = enc_sample[:i]\n",
    "    desire = enc_sample[i]\n",
    "    print(tokenizer_bpe.decode(content), \"---->\", tokenizer_bpe.decode([desire]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190a44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59d9f4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "CUDA: Not Found\n",
      "\n",
      "运行以下命令安装:\n",
      "!pip install torch torchvision torchaudio\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def install_pytorch():\n",
    "    cuda_version = None\n",
    "    if 'linux' in sys.platform:\n",
    "        !nvidia-smi --query-gpu=driver_version --format=csv,noheader 2>/dev/null\n",
    "        cuda_version = !nvcc --version 2>/dev/null | grep \"release\" | awk '{print $6}'\n",
    "    print(f\"Python: {sys.version}\\nCUDA: {cuda_version if cuda_version else 'Not Found'}\")\n",
    "\n",
    "    # 生成安装命令\n",
    "    pytorch_command = \"pip install torch torchvision torchaudio\"\n",
    "    if cuda_version:\n",
    "        pytorch_command += \" --index-url https://download.pytorch.org/whl/cu118\"  # 根据CUDA版本调整\n",
    "    print(f\"\\n运行以下命令安装:\\n!{pytorch_command}\")\n",
    "\n",
    "install_pytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62818d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp39-cp39-win_amd64.whl (216.0 MB)\n",
      "     -------------------------------------- 216.0/216.0 MB 9.1 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 15.6 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 14.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (3.6.0)\n",
      "Collecting typing-extensions>=4.10.0\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.9/43.9 kB ? eta 0:00:00\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 14.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\anaconda1\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\anaconda1\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\anaconda1\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\anaconda1\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Installing collected packages: typing-extensions, sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.10.1\n",
      "    Uninstalling sympy-1.10.1:\n",
      "      Successfully uninstalled sympy-1.10.1\n",
      "Successfully installed sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 typing-extensions-4.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3773e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.1\n",
      "Uninstalling torch-2.7.1:\n",
      "  Successfully uninstalled torch-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 167, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_internal\\commands\\uninstall.py\", line 103, in run\n",
      "    uninstall_pathset.commit()\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 424, in commit\n",
      "    self._moved_paths.commit()\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 277, in commit\n",
      "    save_dir.cleanup()\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 173, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 128, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\shutil.py\", line 624, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\shutil.py\", line 629, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"D:\\anaconda\\anaconda1\\lib\\shutil.py\", line 627, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] 拒绝访问。: 'D:\\\\anaconda\\\\anaconda1\\\\Lib\\\\site-packages\\\\~orch\\\\lib\\\\asmjit.dll'\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a94912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchvision 0.22.1\n",
      "Uninstalling torchvision-0.22.1:\n",
      "  Successfully uninstalled torchvision-0.22.1\n",
      "Found existing installation: torchaudio 2.7.1\n",
      "Uninstalling torchaudio-2.7.1:\n",
      "  Successfully uninstalled torchaudio-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torch as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead60317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl (2532.2 MB)\n",
      "     ---------------------------------------- 2.5/2.5 GB 1.2 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "     ---------------------------------------- 6.1/6.1 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\anaconda\\anaconda1\\lib\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 6.2/6.2 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\anaconda1\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\anaconda1\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\anaconda1\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\anaconda1\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e07c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62043588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd2130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffde610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c81d839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fa5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文本转化为token_id并以tensor形式存储\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        \n",
    "        for i in range(0, len(token_ids) - max_length, stride):  # 建立对应的输入和输出toekn_id tensor\n",
    "            input_chunk = token_ids[i: i+ max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)  # 判断长度\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]  # 返回输入和目标tensor中某一行\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "022ef8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv1 = GPTDatasetV1(raw_text, tokenizer_bpe, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f083f6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  40,  473, 1846, 2744]),\n",
       " tensor([ 473, 1846, 2744, 3463]),\n",
       " tensor([1846, 2744, 3463, 7762]),\n",
       " tensor([2744, 3463, 7762,  480]),\n",
       " tensor([3463, 7762,  480,  285]),\n",
       " tensor([ 7762,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,  4856]),\n",
       " tensor([  285, 22464,  4856,   264]),\n",
       " tensor([22464,  4856,   264, 12136]),\n",
       " tensor([ 4856,   264, 12136, 35201]),\n",
       " tensor([  264, 12136, 35201,   313]),\n",
       " tensor([12136, 35201,   313,  4636]),\n",
       " tensor([35201,   313,  4636,   264]),\n",
       " tensor([ 313, 4636,  264, 1695]),\n",
       " tensor([ 4636,   264,  1695, 12637]),\n",
       " tensor([  264,  1695, 12637,  3403]),\n",
       " tensor([ 1695, 12637,  3403,   313]),\n",
       " tensor([12637,  3403,   313,   708]),\n",
       " tensor([3403,  313,  708,  433]),\n",
       " tensor([313, 708, 433, 574]),\n",
       " tensor([708, 433, 574, 912]),\n",
       " tensor([ 433,  574,  912, 2294]),\n",
       " tensor([  574,   912,  2294, 13051]),\n",
       " tensor([  912,  2294, 13051,   311]),\n",
       " tensor([ 2294, 13051,   311,   757]),\n",
       " tensor([13051,   311,   757,   311]),\n",
       " tensor([ 311,  757,  311, 6865]),\n",
       " tensor([ 757,  311, 6865,  430]),\n",
       " tensor([ 311, 6865,  430,   11]),\n",
       " tensor([6865,  430,   11,  304]),\n",
       " tensor([430,  11, 304, 279]),\n",
       " tensor([  11,  304,  279, 2673]),\n",
       " tensor([ 304,  279, 2673,  315]),\n",
       " tensor([ 279, 2673,  315,  813]),\n",
       " tensor([ 2673,   315,   813, 27025]),\n",
       " tensor([  315,   813, 27025,    11]),\n",
       " tensor([  813, 27025,    11,   568]),\n",
       " tensor([27025,    11,   568,  1047]),\n",
       " tensor([   11,   568,  1047, 12504]),\n",
       " tensor([  568,  1047, 12504,   813]),\n",
       " tensor([ 1047, 12504,   813, 19354]),\n",
       " tensor([12504,   813, 19354,    11]),\n",
       " tensor([  813, 19354,    11, 12502]),\n",
       " tensor([19354,    11, 12502,   264]),\n",
       " tensor([   11, 12502,   264,  9257]),\n",
       " tensor([12502,   264,  9257, 57896]),\n",
       " tensor([  264,  9257, 57896,    11]),\n",
       " tensor([ 9257, 57896,    11,   323]),\n",
       " tensor([57896,    11,   323,  9749]),\n",
       " tensor([  11,  323, 9749, 5678]),\n",
       " tensor([ 323, 9749, 5678,  304]),\n",
       " tensor([9749, 5678,  304,  264]),\n",
       " tensor([ 5678,   304,   264, 47625]),\n",
       " tensor([  304,   264, 47625,   389]),\n",
       " tensor([  264, 47625,   389,   279]),\n",
       " tensor([47625,   389,   279, 51768]),\n",
       " tensor([  389,   279, 51768, 26919]),\n",
       " tensor([  279, 51768, 26919,    13]),\n",
       " tensor([51768, 26919,    13,   320]),\n",
       " tensor([26919,    13,   320, 27831]),\n",
       " tensor([   13,   320, 27831,   358]),\n",
       " tensor([  320, 27831,   358,  4856]),\n",
       " tensor([27831,   358,  4856,  3463]),\n",
       " tensor([ 358, 4856, 3463,  433]),\n",
       " tensor([4856, 3463,  433, 1053]),\n",
       " tensor([3463,  433, 1053,  617]),\n",
       " tensor([ 433, 1053,  617, 1027]),\n",
       " tensor([ 1053,   617,  1027, 22463]),\n",
       " tensor([  617,  1027, 22463,   477]),\n",
       " tensor([ 1027, 22463,   477, 48606]),\n",
       " tensor([22463,   477, 48606,  9456]),\n",
       " tensor([  477, 48606,  9456, 10227]),\n",
       " tensor([48606,  9456, 10227,  2673]),\n",
       " tensor([ 9456, 10227,  2673,   315]),\n",
       " tensor([10227,  2673,   315,   813]),\n",
       " tensor([ 2673,   315,   813, 27025]),\n",
       " tensor([  315,   813, 27025, 75857]),\n",
       " tensor([  813, 27025, 75857,  9210]),\n",
       " tensor([27025, 75857,  9210,   574]),\n",
       " tensor([75857,  9210,   574,  1148]),\n",
       " tensor([9210,  574, 1148,  279]),\n",
       " tensor([ 574, 1148,  279, 3278]),\n",
       " tensor([1148,  279, 3278, 2663]),\n",
       " tensor([ 279, 3278, 2663,  433]),\n",
       " tensor([3278, 2663,  433,   13]),\n",
       " tensor([2663,  433,   13,  358]),\n",
       " tensor([433,  13, 358, 649]),\n",
       " tensor([  13,  358,  649, 6865]),\n",
       " tensor([  358,   649,  6865, 18083]),\n",
       " tensor([  649,  6865, 18083,    13]),\n",
       " tensor([ 6865, 18083,    13,   480]),\n",
       " tensor([ 18083,     13,    480, 100242]),\n",
       " tensor([    13,    480, 100242,    666]),\n",
       " tensor([   480, 100242,    666,  24510]),\n",
       " tensor([100242,    666,  24510,    313]),\n",
       " tensor([  666, 24510,   313, 26301]),\n",
       " tensor([24510,   313, 26301,  1566]),\n",
       " tensor([  313, 26301,  1566, 10780]),\n",
       " tensor([26301,  1566, 10780,  2503]),\n",
       " tensor([ 1566, 10780,  2503,   466]),\n",
       " tensor([10780,  2503,   466,   313]),\n",
       " tensor([2503,  466,  313,  451]),\n",
       " tensor([466, 313, 451, 501]),\n",
       " tensor([ 313,  451,  501, 5620]),\n",
       " tensor([ 451,  501, 5620,  813]),\n",
       " tensor([ 501, 5620,  813,  653]),\n",
       " tensor([5620,  813,  653, 4711]),\n",
       " tensor([ 813,  653, 4711,  481]),\n",
       " tensor([ 653, 4711,  481,  671]),\n",
       " tensor([4711,  481,  671,   67]),\n",
       " tensor([  481,   671,    67, 20901]),\n",
       " tensor([  671,    67, 20901,    13]),\n",
       " tensor([   67, 20901,    13,   330]),\n",
       " tensor([20901,    13,   330,  2173]),\n",
       " tensor([  13,  330, 2173, 3388]),\n",
       " tensor([ 330, 2173, 3388,  433]),\n",
       " tensor([2173, 3388,  433,  596]),\n",
       " tensor([3388,  433,  596, 2133]),\n",
       " tensor([ 433,  596, 2133,  311]),\n",
       " tensor([ 596, 2133,  311, 3708]),\n",
       " tensor([2133,  311, 3708,  279]),\n",
       " tensor([ 311, 3708,  279,  907]),\n",
       " tensor([3708,  279,  907,  315]),\n",
       " tensor([279, 907, 315, 856]),\n",
       " tensor([ 907,  315,  856, 6945]),\n",
       " tensor([ 315,  856, 6945,  364]),\n",
       " tensor([ 856, 6945,  364, 3195]),\n",
       " tensor([6945,  364, 3195,  709]),\n",
       " tensor([ 364, 3195,  709,   26]),\n",
       " tensor([3195,  709,   26,  719]),\n",
       " tensor([709,  26, 719, 358]),\n",
       " tensor([  26,  719,  358, 1541]),\n",
       " tensor([ 719,  358, 1541,  956]),\n",
       " tensor([ 358, 1541,  956, 1781]),\n",
       " tensor([1541,  956, 1781,  315]),\n",
       " tensor([ 956, 1781,  315,  430]),\n",
       " tensor([1781,  315,  430,   11]),\n",
       " tensor([ 315,  430,   11, 4491]),\n",
       " tensor([ 430,   11, 4491,   13]),\n",
       " tensor([   11,  4491,    13, 23194]),\n",
       " tensor([ 4491,    13, 23194,  5721]),\n",
       " tensor([   13, 23194,  5721,   313]),\n",
       " tensor([23194,  5721,   313,  1820]),\n",
       " tensor([5721,  313, 1820, 4814]),\n",
       " tensor([ 313, 1820, 4814,  311]),\n",
       " tensor([ 1820,  4814,   311, 18925]),\n",
       " tensor([ 4814,   311, 18925,    83]),\n",
       " tensor([  311, 18925,    83,   374]),\n",
       " tensor([18925,    83,   374,   682]),\n",
       " tensor([ 83, 374, 682, 358]),\n",
       " tensor([ 374,  682,  358, 1781]),\n",
       " tensor([ 682,  358, 1781,  315]),\n",
       " tensor([ 358, 1781,  315, 1210]),\n",
       " tensor([1781,  315, 1210,  578]),\n",
       " tensor([ 315, 1210,  578, 3492]),\n",
       " tensor([1210,  578, 3492,   11]),\n",
       " tensor([ 578, 3492,   11,  389]),\n",
       " tensor([ 3492,    11,   389, 18083]),\n",
       " tensor([   11,   389, 18083,    13]),\n",
       " tensor([  389, 18083,    13,   666]),\n",
       " tensor([18083,    13,   666, 24510]),\n",
       " tensor([   13,   666, 24510,   596]),\n",
       " tensor([  666, 24510,   596, 23726]),\n",
       " tensor([24510,   596, 23726,    11]),\n",
       " tensor([  596, 23726,    11, 56016]),\n",
       " tensor([23726,    11, 56016,  1202]),\n",
       " tensor([   11, 56016,  1202,   721]),\n",
       " tensor([56016,  1202,   721,  5544]),\n",
       " tensor([1202,  721, 5544,   62]),\n",
       " tensor([ 721, 5544,   62,  439]),\n",
       " tensor([5544,   62,  439, 3582]),\n",
       " tensor([  62,  439, 3582,  814]),\n",
       " tensor([ 439, 3582,  814, 1051]),\n",
       " tensor([ 3582,   814,  1051, 27000]),\n",
       " tensor([  814,  1051, 27000,   304]),\n",
       " tensor([ 1051, 27000,   304,   459]),\n",
       " tensor([27000,   304,   459, 26762]),\n",
       " tensor([  304,   459, 26762, 40136]),\n",
       " tensor([  459, 26762, 40136,   315]),\n",
       " tensor([26762, 40136,   315, 41585]),\n",
       " tensor([40136,   315, 41585,    13]),\n",
       " tensor([  315, 41585,    13,  1628]),\n",
       " tensor([41585,    13,  1628,   433]),\n",
       " tensor([  13, 1628,  433,  574]),\n",
       " tensor([1628,  433,  574,  539]),\n",
       " tensor([ 433,  574,  539, 1193]),\n",
       " tensor([ 574,  539, 1193,  279]),\n",
       " tensor([  539,  1193,   279, 18083]),\n",
       " tensor([ 1193,   279, 18083,    13]),\n",
       " tensor([  279, 18083,    13,   666]),\n",
       " tensor([18083,    13,   666,    86]),\n",
       " tensor([ 13, 666,  86, 826]),\n",
       " tensor([666,  86, 826, 889]),\n",
       " tensor([   86,   826,   889, 60234]),\n",
       " tensor([  826,   889, 60234,   291]),\n",
       " tensor([  889, 60234,   291,    13]),\n",
       " tensor([60234,   291,    13, 24805]),\n",
       " tensor([  291,    13, 24805,   539]),\n",
       " tensor([   13, 24805,   539,   279]),\n",
       " tensor([24805,   539,   279, 59708]),\n",
       " tensor([  539,   279, 59708, 32565]),\n",
       " tensor([  279, 59708, 32565,   689]),\n",
       " tensor([59708, 32565,   689, 25611]),\n",
       " tensor([32565,   689, 25611,   728]),\n",
       " tensor([  689, 25611,   728,    11]),\n",
       " tensor([25611,   728,    11,   520]),\n",
       " tensor([728,  11, 520, 279]),\n",
       " tensor([  11,  520,  279, 1566]),\n",
       " tensor([ 520,  279, 1566,  480]),\n",
       " tensor([ 279, 1566,  480, 3017]),\n",
       " tensor([1566,  480, 3017,  263]),\n",
       " tensor([  480,  3017,   263, 19853]),\n",
       " tensor([ 3017,   263, 19853,  1501]),\n",
       " tensor([  263, 19853,  1501,    11]),\n",
       " tensor([19853,  1501,    11, 10717]),\n",
       " tensor([ 1501,    11, 10717,   757]),\n",
       " tensor([   11, 10717,   757,  1603]),\n",
       " tensor([10717,   757,  1603,   480]),\n",
       " tensor([ 757, 1603,  480,  285]),\n",
       " tensor([ 1603,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,   596]),\n",
       " tensor([  285, 22464,   596,   330]),\n",
       " tensor([22464,   596,   330, 77119]),\n",
       " tensor([  596,   330, 77119,  1773]),\n",
       " tensor([  330, 77119,  1773, 32842]),\n",
       " tensor([77119,  1773, 32842,     1]),\n",
       " tensor([ 1773, 32842,     1,   311]),\n",
       " tensor([32842,     1,   311,  2019]),\n",
       " tensor([   1,  311, 2019,   11]),\n",
       " tensor([ 311, 2019,   11,  449]),\n",
       " tensor([ 2019,    11,   449, 24014]),\n",
       " tensor([   11,   449, 24014,   304]),\n",
       " tensor([  449, 24014,   304,  1077]),\n",
       " tensor([24014,   304,  1077,  6548]),\n",
       " tensor([ 304, 1077, 6548,   25]),\n",
       " tensor([1077, 6548,   25,  330]),\n",
       " tensor([6548,   25,  330, 1687]),\n",
       " tensor([  25,  330, 1687, 4985]),\n",
       " tensor([ 330, 1687, 4985,  539]),\n",
       " tensor([1687, 4985,  539, 1427]),\n",
       " tensor([4985,  539, 1427, 5304]),\n",
       " tensor([ 539, 1427, 5304, 1202]),\n",
       " tensor([1427, 5304, 1202, 1093]),\n",
       " tensor([5304, 1202, 1093, 1578]),\n",
       " tensor([ 1202,  1093,  1578, 94770]),\n",
       " tensor([ 1093,  1578, 94770, 11649]),\n",
       " tensor([ 1578, 94770, 11649,  2556]),\n",
       " tensor([94770, 11649,  2556, 17206]),\n",
       " tensor([11649,  2556, 17206,  1555]),\n",
       " tensor([ 2556, 17206,  1555,   279]),\n",
       " tensor([17206,  1555,   279, 94710]),\n",
       " tensor([ 1555,   279, 94710,   315]),\n",
       " tensor([  279, 94710,   315, 32565]),\n",
       " tensor([94710,   315, 32565,   689]),\n",
       " tensor([  315, 32565,   689,   596]),\n",
       " tensor([32565,   689,   596, 24014]),\n",
       " tensor([  689,   596, 24014,   358]),\n",
       " tensor([  596, 24014,   358,  6612]),\n",
       " tensor([24014,   358,  6612,  3025]),\n",
       " tensor([ 358, 6612, 3025,  311]),\n",
       " tensor([6612, 3025,  311, 3663]),\n",
       " tensor([3025,  311, 3663,  279]),\n",
       " tensor([ 311, 3663,  279, 2144]),\n",
       " tensor([3663,  279, 2144,  449]),\n",
       " tensor([ 279, 2144,  449, 3312]),\n",
       " tensor([ 2144,   449,  3312, 16348]),\n",
       " tensor([  449,  3312, 16348,   488]),\n",
       " tensor([ 3312, 16348,   488,    13]),\n",
       " tensor([16348,   488,    13, 45773]),\n",
       " tensor([  488,    13, 45773,  7762]),\n",
       " tensor([   13, 45773,  7762,   480]),\n",
       " tensor([45773,  7762,   480,   285]),\n",
       " tensor([ 7762,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,     0]),\n",
       " tensor([  285, 22464,     0,   578]),\n",
       " tensor([22464,     0,   578,  3278]),\n",
       " tensor([   0,  578, 3278, 1047]),\n",
       " tensor([ 578, 3278, 1047, 1903]),\n",
       " tensor([3278, 1047, 1903, 1461]),\n",
       " tensor([1047, 1903, 1461,  313]),\n",
       " tensor([1903, 1461,  313,  275]),\n",
       " tensor([1461,  313,  275,  574]),\n",
       " tensor([  313,   275,   574, 27442]),\n",
       " tensor([  275,   574, 27442,   430]),\n",
       " tensor([  574, 27442,   430,   814]),\n",
       " tensor([27442,   430,   814,  1288]),\n",
       " tensor([  430,   814,  1288, 60234]),\n",
       " tensor([  814,  1288, 60234,  1461]),\n",
       " tensor([ 1288, 60234,  1461,    13]),\n",
       " tensor([60234,  1461,    13, 22395]),\n",
       " tensor([ 1461,    13, 22395,   813]),\n",
       " tensor([   13, 22395,   813,  1866]),\n",
       " tensor([22395,   813,  1866,  1877]),\n",
       " tensor([  813,  1866,  1877, 17162]),\n",
       " tensor([ 1866,  1877, 17162, 69025]),\n",
       " tensor([ 1877, 17162, 69025,  1051]),\n",
       " tensor([17162, 69025,  1051,  6755]),\n",
       " tensor([69025,  1051,  6755,    11]),\n",
       " tensor([1051, 6755,   11,  323]),\n",
       " tensor([6755,   11,  323,  304]),\n",
       " tensor([ 11, 323, 304, 813]),\n",
       " tensor([ 323,  304,  813, 1866]),\n",
       " tensor([ 304,  813, 1866, 6696]),\n",
       " tensor([  813,  1866,  6696, 20781]),\n",
       " tensor([ 1866,  6696, 20781,   264]),\n",
       " tensor([ 6696, 20781,   264,  8309]),\n",
       " tensor([20781,   264,  8309, 66206]),\n",
       " tensor([  264,  8309, 66206,    13]),\n",
       " tensor([ 8309, 66206,    13, 21931]),\n",
       " tensor([66206,    13, 21931, 80822]),\n",
       " tensor([   13, 21931, 80822,    30]),\n",
       " tensor([21931, 80822,    30, 19292]),\n",
       " tensor([80822,    30, 19292,    13]),\n",
       " tensor([   30, 19292,    13,  1442]),\n",
       " tensor([19292,    13,  1442,   433]),\n",
       " tensor([  13, 1442,  433, 1051]),\n",
       " tensor([1442,  433, 1051,   11]),\n",
       " tensor([ 433, 1051,   11,  279]),\n",
       " tensor([ 1051,    11,   279, 34662]),\n",
       " tensor([   11,   279, 34662,   315]),\n",
       " tensor([  279, 34662,   315,   279]),\n",
       " tensor([34662,   315,   279, 11003]),\n",
       " tensor([  315,   279, 11003,   574]),\n",
       " tensor([  279, 11003,   574, 38905]),\n",
       " tensor([11003,   574, 38905, 10297]),\n",
       " tensor([  574, 38905, 10297,   555]),\n",
       " tensor([38905, 10297,   555,  2697]),\n",
       " tensor([10297,   555,  2697, 75430]),\n",
       " tensor([  555,  2697, 75430, 18878]),\n",
       " tensor([ 2697, 75430, 18878,  3258]),\n",
       " tensor([75430, 18878,  3258,    11]),\n",
       " tensor([18878,  3258,    11,   889]),\n",
       " tensor([3258,   11,  889,   11]),\n",
       " tensor([ 11, 889,  11, 304]),\n",
       " tensor([889,  11, 304, 682]),\n",
       " tensor([  11,  304,  682, 1695]),\n",
       " tensor([  304,   682,  1695, 10082]),\n",
       " tensor([  682,  1695, 10082,    11]),\n",
       " tensor([ 1695, 10082,    11,  7263]),\n",
       " tensor([10082,    11,  7263,   704]),\n",
       " tensor([  11, 7263,  704,  304]),\n",
       " tensor([7263,  704,  304,  279]),\n",
       " tensor([  704,   304,   279, 73605]),\n",
       " tensor([  304,   279, 73605,   264]),\n",
       " tensor([  279, 73605,   264,  1633]),\n",
       " tensor([73605,   264,  1633, 44877]),\n",
       " tensor([  264,  1633, 44877,   330]),\n",
       " tensor([ 1633, 44877,   330,   677]),\n",
       " tensor([44877,   330,   677,   275]),\n",
       " tensor([ 330,  677,  275, 3620]),\n",
       " tensor([ 677,  275, 3620,    1]),\n",
       " tensor([ 275, 3620,    1,  389]),\n",
       " tensor([3620,    1,  389, 7762]),\n",
       " tensor([   1,  389, 7762,  313]),\n",
       " tensor([ 389, 7762,  313,  606]),\n",
       " tensor([7762,  313,  606,  315]),\n",
       " tensor([ 313,  606,  315, 1884]),\n",
       " tensor([ 606,  315, 1884, 1501]),\n",
       " tensor([ 315, 1884, 1501,   88]),\n",
       " tensor([1884, 1501,   88, 9908]),\n",
       " tensor([ 1501,    88,  9908, 71116]),\n",
       " tensor([   88,  9908, 71116,   449]),\n",
       " tensor([ 9908, 71116,   449,  4288]),\n",
       " tensor([71116,   449,  4288, 11156]),\n",
       " tensor([  449,  4288, 11156,  1385]),\n",
       " tensor([ 4288, 11156,  1385,   430]),\n",
       " tensor([11156,  1385,   430,   358]),\n",
       " tensor([1385,  430,  358,  617]),\n",
       " tensor([ 430,  358,  617, 6755]),\n",
       " tensor([ 358,  617, 6755,  320]),\n",
       " tensor([ 617, 6755,  320,   40]),\n",
       " tensor([6755,  320,   40, 2834]),\n",
       " tensor([ 320,   40, 2834,  956]),\n",
       " tensor([  40, 2834,  956, 2019]),\n",
       " tensor([2834,  956, 2019,  555]),\n",
       " tensor([ 956, 2019,  555, 8884]),\n",
       " tensor([2019,  555, 8884,    8]),\n",
       " tensor([ 555, 8884,    8, 7863]),\n",
       " tensor([8884,    8, 7863,  311]),\n",
       " tensor([   8, 7863,  311,  480]),\n",
       " tensor([7863,  311,  480,  285]),\n",
       " tensor([  311,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,   596]),\n",
       " tensor([  285, 22464,   596, 19354]),\n",
       " tensor([22464,   596, 19354,    13]),\n",
       " tensor([  596, 19354,    13,  1628]),\n",
       " tensor([19354,    13,  1628,   779]),\n",
       " tensor([  13, 1628,  779,  313]),\n",
       " tensor([ 1628,   779,   313, 26301]),\n",
       " tensor([  779,   313, 26301,  9006]),\n",
       " tensor([  313, 26301,  9006,  1694]),\n",
       " tensor([26301,  9006,  1694, 14132]),\n",
       " tensor([ 9006,  1694, 14132,  6348]),\n",
       " tensor([ 1694, 14132,  6348,  7430]),\n",
       " tensor([14132,  6348,  7430,   511]),\n",
       " tensor([6348, 7430,  511,  481]),\n",
       " tensor([7430,  511,  481,  313]),\n",
       " tensor([ 511,  481,  313, 1820]),\n",
       " tensor([  481,   313,  1820, 10430]),\n",
       " tensor([  313,  1820, 10430, 27115]),\n",
       " tensor([ 1820, 10430, 27115,  8636]),\n",
       " tensor([10430, 27115,  8636,   704]),\n",
       " tensor([27115,  8636,   704,    11]),\n",
       " tensor([8636,  704,   11,  323]),\n",
       " tensor([704,  11, 323,  11]),\n",
       " tensor([ 11, 323,  11, 439]),\n",
       " tensor([  323,    11,   439, 18083]),\n",
       " tensor([   11,   439, 18083,    13]),\n",
       " tensor([  439, 18083,    13,   666]),\n",
       " tensor([18083,    13,   666, 24510]),\n",
       " tensor([   13,   666, 24510,  1047]),\n",
       " tensor([  666, 24510,  1047, 19698]),\n",
       " tensor([24510,  1047, 19698,    11]),\n",
       " tensor([ 1047, 19698,    11,   279]),\n",
       " tensor([19698,    11,   279,  3430]),\n",
       " tensor([  11,  279, 3430,  315]),\n",
       " tensor([ 279, 3430,  315,  330]),\n",
       " tensor([3430,  315,  330,   38]),\n",
       " tensor([315, 330,  38, 285]),\n",
       " tensor([  330,    38,   285, 22464]),\n",
       " tensor([   38,   285, 22464,    82]),\n",
       " tensor([  285, 22464,    82,     1]),\n",
       " tensor([22464,    82,     1,  4024]),\n",
       " tensor([  82,    1, 4024,  709]),\n",
       " tensor([   1, 4024,  709,  382]),\n",
       " tensor([4024,  709,  382, 2181]),\n",
       " tensor([ 709,  382, 2181,  574]),\n",
       " tensor([ 382, 2181,  574,  539]),\n",
       " tensor([ 2181,   574,   539, 12222]),\n",
       " tensor([  574,   539, 12222,  2380]),\n",
       " tensor([  539, 12222,  2380,  1667]),\n",
       " tensor([12222,  2380,  1667,  3010]),\n",
       " tensor([2380, 1667, 3010,  430]),\n",
       " tensor([1667, 3010,  430,   11]),\n",
       " tensor([3010,  430,   11,  304]),\n",
       " tensor([430,  11, 304, 279]),\n",
       " tensor([  11,  304,  279, 3388]),\n",
       " tensor([ 304,  279, 3388,  315]),\n",
       " tensor([ 279, 3388,  315,  264]),\n",
       " tensor([3388,  315,  264, 2478]),\n",
       " tensor([ 315,  264, 2478, 5672]),\n",
       " tensor([ 264, 2478, 5672,    6]),\n",
       " tensor([2478, 5672,    6,  887]),\n",
       " tensor([5672,    6,  887, 2785]),\n",
       " tensor([   6,  887, 2785,  389]),\n",
       " tensor([ 887, 2785,  389,  279]),\n",
       " tensor([ 2785,   389,   279, 51768]),\n",
       " tensor([  389,   279, 51768, 26919]),\n",
       " tensor([  279, 51768, 26919,    11]),\n",
       " tensor([51768, 26919,    11,   433]),\n",
       " tensor([26919,    11,   433, 15187]),\n",
       " tensor([   11,   433, 15187, 10222]),\n",
       " tensor([  433, 15187, 10222,   311]),\n",
       " tensor([15187, 10222,   311,   757]),\n",
       " tensor([10222,   311,   757,   311]),\n",
       " tensor([ 311,  757,  311, 5895]),\n",
       " tensor([ 757,  311, 5895, 3249]),\n",
       " tensor([ 311, 5895, 3249,  480]),\n",
       " tensor([5895, 3249,  480,  285]),\n",
       " tensor([ 3249,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,  1047]),\n",
       " tensor([  285, 22464,  1047,  2728]),\n",
       " tensor([22464,  1047,  2728,   709]),\n",
       " tensor([1047, 2728,  709,  813]),\n",
       " tensor([ 2728,   709,   813, 19354]),\n",
       " tensor([  709,   813, 19354,    13]),\n",
       " tensor([  813, 19354,    13,  1952]),\n",
       " tensor([19354,    13,  1952, 22599]),\n",
       " tensor([   13,  1952, 22599,    11]),\n",
       " tensor([ 1952, 22599,    11,   433]),\n",
       " tensor([22599,    11,   433,  2216]),\n",
       " tensor([  11,  433, 2216,  574]),\n",
       " tensor([ 433, 2216,  574,  264]),\n",
       " tensor([ 2216,   574,   264, 61299]),\n",
       " tensor([  574,   264, 61299,  3575]),\n",
       " tensor([  264, 61299,  3575,    13]),\n",
       " tensor([61299,  3575,    13,  2057]),\n",
       " tensor([ 3575,    13,  2057, 62742]),\n",
       " tensor([   13,  2057, 62742,   813]),\n",
       " tensor([ 2057, 62742,   813,  7555]),\n",
       " tensor([62742,   813,  7555,  1053]),\n",
       " tensor([ 813, 7555, 1053,  617]),\n",
       " tensor([7555, 1053,  617, 1027]),\n",
       " tensor([1053,  617, 1027, 2288]),\n",
       " tensor([ 617, 1027, 2288, 4228]),\n",
       " tensor([1027, 2288, 4228,  313]),\n",
       " tensor([ 2288,  4228,   313, 26301]),\n",
       " tensor([ 4228,   313, 26301,  6762]),\n",
       " tensor([  313, 26301,  6762,   274]),\n",
       " tensor([26301,  6762,   274, 29163]),\n",
       " tensor([ 6762,   274, 29163,  1047]),\n",
       " tensor([  274, 29163,  1047,  1027]),\n",
       " tensor([29163,  1047,  1027, 15164]),\n",
       " tensor([ 1047,  1027, 15164,   279]),\n",
       " tensor([ 1027, 15164,   279,  2092]),\n",
       " tensor([15164,   279,  2092,   580]),\n",
       " tensor([ 279, 2092,  580,  315]),\n",
       " tensor([2092,  580,  315, 5605]),\n",
       " tensor([ 580,  315, 5605,  430]),\n",
       " tensor([  315,  5605,   430, 18083]),\n",
       " tensor([ 5605,   430, 18083,    13]),\n",
       " tensor([  430, 18083,    13,   480]),\n",
       " tensor([18083,    13,   480,   285]),\n",
       " tensor([   13,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,  1047]),\n",
       " tensor([  285, 22464,  1047,   330]),\n",
       " tensor([22464,  1047,   330, 35031]),\n",
       " tensor([ 1047,   330, 35031,  3640]),\n",
       " tensor([  330, 35031,  3640,  1461]),\n",
       " tensor([35031,  3640,  1461,  1523]),\n",
       " tensor([3640, 1461, 1523, 1210]),\n",
       " tensor([1461, 1523, 1210, 1789]),\n",
       " tensor([ 1523,  1210,  1789, 18083]),\n",
       " tensor([ 1210,  1789, 18083,    13]),\n",
       " tensor([ 1789, 18083,    13,   480]),\n",
       " tensor([18083,    13,   480,   285]),\n",
       " tensor([   13,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,   313]),\n",
       " tensor([  285, 22464,   313,   300]),\n",
       " tensor([22464,   313,   300,  1778]),\n",
       " tensor([ 313,  300, 1778,  313]),\n",
       " tensor([  300,  1778,   313, 32345]),\n",
       " tensor([ 1778,   313, 32345,   539]),\n",
       " tensor([  313, 32345,   539, 25281]),\n",
       " tensor([32345,   539, 25281, 12222]),\n",
       " tensor([  539, 25281, 12222,  7154]),\n",
       " tensor([25281, 12222,  7154,   264]),\n",
       " tensor([12222,  7154,   264,  1060]),\n",
       " tensor([7154,  264, 1060, 1306]),\n",
       " tensor([ 264, 1060, 1306, 7762]),\n",
       " tensor([1060, 1306, 7762,  596]),\n",
       " tensor([1306, 7762,  596, 9006]),\n",
       " tensor([7762,  596, 9006, 1047]),\n",
       " tensor([ 596, 9006, 1047, 1027]),\n",
       " tensor([9006, 1047, 1027, 4529]),\n",
       " tensor([1047, 1027, 4529,   13]),\n",
       " tensor([1027, 4529,   13, 1102]),\n",
       " tensor([4529,   13, 1102, 2643]),\n",
       " tensor([  13, 1102, 2643,  387]),\n",
       " tensor([1102, 2643,  387,  430]),\n",
       " tensor([2643,  387,  430,  568]),\n",
       " tensor([ 387,  430,  568, 1047]),\n",
       " tensor([  430,   568,  1047, 12502]),\n",
       " tensor([  568,  1047, 12502,  1077]),\n",
       " tensor([ 1047, 12502,  1077,   313]),\n",
       " tensor([12502,  1077,   313, 11536]),\n",
       " tensor([ 1077,   313, 11536,   568]),\n",
       " tensor([  313, 11536,   568, 15262]),\n",
       " tensor([11536,   568, 15262,   813]),\n",
       " tensor([  568, 15262,   813, 14553]),\n",
       " tensor([15262,   813, 14553,   313]),\n",
       " tensor([  813, 14553,   313, 28753]),\n",
       " tensor([14553,   313, 28753,   568]),\n",
       " tensor([  313, 28753,   568,  3287]),\n",
       " tensor([28753,   568,  3287,   956]),\n",
       " tensor([ 568, 3287,  956, 1390]),\n",
       " tensor([3287,  956, 1390,  311]),\n",
       " tensor([ 956, 1390,  311,  733]),\n",
       " tensor([1390,  311,  733,  389]),\n",
       " tensor([  311,   733,   389, 19354]),\n",
       " tensor([  733,   389, 19354,    26]),\n",
       " tensor([  389, 19354,    26,   719]),\n",
       " tensor([19354,    26,   719,   433]),\n",
       " tensor([  26,  719,  433, 1053]),\n",
       " tensor([ 719,  433, 1053,  617]),\n",
       " tensor([ 433, 1053,  617, 1027]),\n",
       " tensor([1053,  617, 1027, 2653]),\n",
       " tensor([ 617, 1027, 2653,  311]),\n",
       " tensor([ 1027,  2653,   311, 12391]),\n",
       " tensor([ 2653,   311, 12391,   430]),\n",
       " tensor([  311, 12391,   430,   568]),\n",
       " tensor([12391,   430,   568,  1047]),\n",
       " tensor([ 430,  568, 1047, 2728]),\n",
       " tensor([ 568, 1047, 2728,  709]),\n",
       " tensor([1047, 2728,  709,  813]),\n",
       " tensor([ 2728,   709,   813, 19354]),\n",
       " tensor([  709,   813, 19354,  1606]),\n",
       " tensor([  813, 19354,  1606,   568]),\n",
       " tensor([19354,  1606,   568,  1047]),\n",
       " tensor([ 1606,   568,  1047, 12502]),\n",
       " tensor([  568,  1047, 12502,  1077]),\n",
       " tensor([ 1047, 12502,  1077,   382]),\n",
       " tensor([12502,  1077,   382,  2173]),\n",
       " tensor([1077,  382, 2173, 3388]),\n",
       " tensor([ 382, 2173, 3388,   11]),\n",
       " tensor([2173, 3388,   11,  422]),\n",
       " tensor([3388,   11,  422, 1364]),\n",
       " tensor([  11,  422, 1364, 1047]),\n",
       " tensor([ 422, 1364, 1047,  539]),\n",
       " tensor([ 1364,  1047,   539, 38247]),\n",
       " tensor([ 1047,   539, 38247,  1461]),\n",
       " tensor([  539, 38247,  1461,  1523]),\n",
       " tensor([38247,  1461,  1523,    11]),\n",
       " tensor([1461, 1523,   11, 1364]),\n",
       " tensor([1523,   11, 1364, 1047]),\n",
       " tensor([   11,  1364,  1047, 18813]),\n",
       " tensor([ 1364,  1047, 18813,    11]),\n",
       " tensor([ 1047, 18813,    11,   439]),\n",
       " tensor([18813,    11,   439,  9083]),\n",
       " tensor([   11,   439,  9083, 25611]),\n",
       " tensor([  439,  9083, 25611,   728]),\n",
       " tensor([ 9083, 25611,   728,   687]),\n",
       " tensor([25611,   728,   687,  2954]),\n",
       " tensor([ 728,  687, 2954,   11]),\n",
       " tensor([ 687, 2954,   11, 4745]),\n",
       " tensor([2954,   11, 4745,  311]),\n",
       " tensor([  11, 4745,  311,  330]),\n",
       " tensor([ 4745,   311,   330, 36069]),\n",
       " tensor([  311,   330, 36069,  1461]),\n",
       " tensor([  330, 36069,  1461,   709]),\n",
       " tensor([36069,  1461,   709, 75857]),\n",
       " tensor([ 1461,   709, 75857, 32158]),\n",
       " tensor([  709, 75857, 32158,  1047]),\n",
       " tensor([75857, 32158,  1047,   539]),\n",
       " tensor([32158,  1047,   539,  6197]),\n",
       " tensor([1047,  539, 6197, 1461]),\n",
       " tensor([ 539, 6197, 1461, 1203]),\n",
       " tensor([6197, 1461, 1203,  311]),\n",
       " tensor([1461, 1203,  311,  279]),\n",
       " tensor([1203,  311,  279, 2593]),\n",
       " tensor([ 311,  279, 2593,  301]),\n",
       " tensor([ 279, 2593,  301,   13]),\n",
       " tensor([2593,  301,   13, 2057]),\n",
       " tensor([ 301,   13, 2057, 2231]),\n",
       " tensor([  13, 2057, 2231,  279]),\n",
       " tensor([ 2057,  2231,   279, 15998]),\n",
       " tensor([ 2231,   279, 15998,  1139]),\n",
       " tensor([  279, 15998,  1139,   813]),\n",
       " tensor([15998,  1139,   813,  1450]),\n",
       " tensor([1139,  813, 1450, 1578]),\n",
       " tensor([ 813, 1450, 1578,  313]),\n",
       " tensor([ 1450,  1578,   313, 12840]),\n",
       " tensor([ 1578,   313, 12840,   264]),\n",
       " tensor([  313, 12840,   264,   348]),\n",
       " tensor([12840,   264,   348,  2328]),\n",
       " tensor([ 264,  348, 2328,  369]),\n",
       " tensor([ 348, 2328,  369,  264]),\n",
       " tensor([2328,  369,  264, 7555]),\n",
       " tensor([ 369,  264, 7555,    0]),\n",
       " tensor([ 264, 7555,    0, 2030]),\n",
       " tensor([ 7555,     0,  2030, 18083]),\n",
       " tensor([    0,  2030, 18083,    13]),\n",
       " tensor([ 2030, 18083,    13,   480]),\n",
       " tensor([18083,    13,   480,   285]),\n",
       " tensor([   13,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,  9922]),\n",
       " tensor([  285, 22464,  9922,   311]),\n",
       " tensor([22464,  9922,   311,   617]),\n",
       " tensor([9922,  311,  617,  834]),\n",
       " tensor([311, 617, 834,  67]),\n",
       " tensor([ 617,  834,   67, 2692]),\n",
       " tensor([ 834,   67, 2692,  433]),\n",
       " tensor([  67, 2692,  433,  313]),\n",
       " tensor([2692,  433,  313,  438]),\n",
       " tensor([433, 313, 438, 358]),\n",
       " tensor([ 313,  438,  358, 6612]),\n",
       " tensor([ 438,  358, 6612,  433]),\n",
       " tensor([ 358, 6612,  433, 2643]),\n",
       " tensor([6612,  433, 2643,  387]),\n",
       " tensor([ 433, 2643,  387, 7185]),\n",
       " tensor([2643,  387, 7185,  311]),\n",
       " tensor([ 387, 7185,  311, 1505]),\n",
       " tensor([7185,  311, 1505,  704]),\n",
       " tensor([ 311, 1505,  704, 3249]),\n",
       " tensor([1505,  704, 3249,  382]),\n",
       " tensor([ 704, 3249,  382,  791]),\n",
       " tensor([3249,  382,  791,  951]),\n",
       " tensor([382, 791, 951, 495]),\n",
       " tensor([791, 951, 495, 683]),\n",
       " tensor([ 951,  495,  683, 2324]),\n",
       " tensor([ 495,  683, 2324,  315]),\n",
       " tensor([ 683, 2324,  315,  279]),\n",
       " tensor([ 2324,   315,   279, 51768]),\n",
       " tensor([  315,   279, 51768, 26919]),\n",
       " tensor([  279, 51768, 26919, 79018]),\n",
       " tensor([51768, 26919, 79018,  5196]),\n",
       " tensor([26919, 79018,  5196,   311]),\n",
       " tensor([79018,  5196,   311,  1778]),\n",
       " tensor([ 5196,   311,  1778, 32227]),\n",
       " tensor([  311,  1778, 32227, 14584]),\n",
       " tensor([ 1778, 32227, 14584,  1424]),\n",
       " tensor([32227, 14584,  1424,  7607]),\n",
       " tensor([14584,  1424,  7607,    26]),\n",
       " tensor([1424, 7607,   26,  323]),\n",
       " tensor([7607,   26,  323, 3515]),\n",
       " tensor([  26,  323, 3515,   11]),\n",
       " tensor([ 323, 3515,   11,  389]),\n",
       " tensor([3515,   11,  389,  856]),\n",
       " tensor([  11,  389,  856, 1648]),\n",
       " tensor([ 389,  856, 1648,  311]),\n",
       " tensor([  856,  1648,   311, 46867]),\n",
       " tensor([ 1648,   311, 46867, 58870]),\n",
       " tensor([  311, 46867, 58870,    11]),\n",
       " tensor([46867, 58870,    11, 10791]),\n",
       " tensor([58870,    11, 10791,   264]),\n",
       " tensor([   11, 10791,   264, 40942]),\n",
       " tensor([10791,   264, 40942,   315]),\n",
       " tensor([  264, 40942,   315,  7762]),\n",
       " tensor([40942,   315,  7762,   596]),\n",
       " tensor([ 315, 7762,  596, 9839]),\n",
       " tensor([7762,  596, 9839, 3497]),\n",
       " tensor([  596,  9839,  3497, 14589]),\n",
       " tensor([ 9839,  3497, 14589,  7317]),\n",
       " tensor([ 3497, 14589,  7317,  2492]),\n",
       " tensor([14589,  7317,  2492,  1990]),\n",
       " tensor([7317, 2492, 1990,  279]),\n",
       " tensor([2492, 1990,  279,  281]),\n",
       " tensor([1990,  279,  281, 1572]),\n",
       " tensor([ 279,  281, 1572,   11]),\n",
       " tensor([ 281, 1572,   11,  358]),\n",
       " tensor([1572,   11,  358, 1047]),\n",
       " tensor([  11,  358, 1047, 7182]),\n",
       " tensor([  358,  1047,  7182, 65162]),\n",
       " tensor([ 1047,  7182, 65162,   270]),\n",
       " tensor([ 7182, 65162,   270,  2544]),\n",
       " tensor([65162,   270,  2544,   279]),\n",
       " tensor([ 270, 2544,  279, 1828]),\n",
       " tensor([2544,  279, 1828, 1938]),\n",
       " tensor([ 279, 1828, 1938,  382]),\n",
       " tensor([1828, 1938,  382,   40]),\n",
       " tensor([1938,  382,   40, 1766]),\n",
       " tensor([ 382,   40, 1766,  279]),\n",
       " tensor([  40, 1766,  279, 5743]),\n",
       " tensor([1766,  279, 5743,  520]),\n",
       " tensor([  279,  5743,   520, 15600]),\n",
       " tensor([ 5743,   520, 15600, 24923]),\n",
       " tensor([  520, 15600, 24923,   872]),\n",
       " tensor([15600, 24923,   872, 33552]),\n",
       " tensor([24923,   872, 33552,  2442]),\n",
       " tensor([  872, 33552,  2442,  8016]),\n",
       " tensor([33552,  2442,  8016,    26]),\n",
       " tensor([2442, 8016,   26,  323]),\n",
       " tensor([ 8016,    26,   323, 18083]),\n",
       " tensor([   26,   323, 18083,    13]),\n",
       " tensor([  323, 18083,    13,   480]),\n",
       " tensor([18083,    13,   480,   285]),\n",
       " tensor([   13,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,   596]),\n",
       " tensor([  285, 22464,   596, 10788]),\n",
       " tensor([22464,   596, 10788,   574]),\n",
       " tensor([  596, 10788,   574,   779]),\n",
       " tensor([10788,   574,   779,  4173]),\n",
       " tensor([ 574,  779, 4173,  532]),\n",
       " tensor([ 779, 4173,  532,  430]),\n",
       " tensor([4173,  532,  430,   11]),\n",
       " tensor([532, 430,  11, 304]),\n",
       " tensor([430,  11, 304, 279]),\n",
       " tensor([   11,   304,   279, 72758]),\n",
       " tensor([  304,   279, 72758,  5672]),\n",
       " tensor([  279, 72758,  5672,    11]),\n",
       " tensor([72758,  5672,    11,   358]),\n",
       " tensor([ 5672,    11,   358, 11922]),\n",
       " tensor([   11,   358, 11922,   433]),\n",
       " tensor([  358, 11922,   433, 14134]),\n",
       " tensor([11922,   433, 14134,    13]),\n",
       " tensor([  433, 14134,    13,  1102]),\n",
       " tensor([14134,    13,  1102,   574]),\n",
       " tensor([  13, 1102,  574,  539]),\n",
       " tensor([1102,  574,  539,  430]),\n",
       " tensor([574, 539, 430, 856]),\n",
       " tensor([ 539,  430,  856, 3552]),\n",
       " tensor([ 430,  856, 3552,  434]),\n",
       " tensor([ 856, 3552,  434,  574]),\n",
       " tensor([3552,  434,  574,  330]),\n",
       " tensor([  434,   574,   330, 88657]),\n",
       " tensor([  574,   330, 88657,   794]),\n",
       " tensor([  330, 88657,   794,   389]),\n",
       " tensor([88657,   794,   389,   430]),\n",
       " tensor([ 794,  389,  430, 1486]),\n",
       " tensor([ 389,  430, 1486,  358]),\n",
       " tensor([ 430, 1486,  358, 1436]),\n",
       " tensor([1486,  358, 1436,  617]),\n",
       " tensor([ 358, 1436,  617, 2728]),\n",
       " tensor([1436,  617, 2728, 9083]),\n",
       " tensor([  617,  2728,  9083, 25611]),\n",
       " tensor([ 2728,  9083, 25611,   728]),\n",
       " tensor([ 9083, 25611,   728,   279]),\n",
       " tensor([25611,   728,   279, 77796]),\n",
       " tensor([  728,   279, 77796, 32834]),\n",
       " tensor([  279, 77796, 32834,  5890]),\n",
       " tensor([77796, 32834,  5890,    13]),\n",
       " tensor([32834,  5890,    13,  1102]),\n",
       " tensor([5890,   13, 1102,  574]),\n",
       " tensor([  13, 1102,  574, 1120]),\n",
       " tensor([1102,  574, 1120, 1606]),\n",
       " tensor([ 574, 1120, 1606, 1364]),\n",
       " tensor([1120, 1606, 1364,  574]),\n",
       " tensor([1606, 1364,  574,  721]),\n",
       " tensor([1364,  574,  721, 1962]),\n",
       " tensor([ 574,  721, 1962,   62]),\n",
       " tensor([ 721, 1962,   62, 7185]),\n",
       " tensor([1962,   62, 7185,  313]),\n",
       " tensor([  62, 7185,  313,  333]),\n",
       " tensor([7185,  313,  333,  358]),\n",
       " tensor([ 313,  333,  358, 1253]),\n",
       " tensor([ 333,  358, 1253,  387]),\n",
       " tensor([  358,  1253,   387, 91047]),\n",
       " tensor([ 1253,   387, 91047, 20262]),\n",
       " tensor([  387, 91047, 20262,   279]),\n",
       " tensor([91047, 20262,   279, 17231]),\n",
       " tensor([20262,   279, 17231,   313]),\n",
       " tensor([  279, 17231,   313,  9210]),\n",
       " tensor([17231,   313,  9210,   358]),\n",
       " tensor([ 313, 9210,  358, 1766]),\n",
       " tensor([9210,  358, 1766, 1077]),\n",
       " tensor([ 358, 1766, 1077,  779]),\n",
       " tensor([1766, 1077,  779,   13]),\n",
       " tensor([1077,  779,   13, 1789]),\n",
       " tensor([ 779,   13, 1789, 7762]),\n",
       " tensor([  13, 1789, 7762,   11]),\n",
       " tensor([1789, 7762,   11,  682]),\n",
       " tensor([7762,   11,  682,  813]),\n",
       " tensor([  11,  682,  813, 2324]),\n",
       " tensor([ 682,  813, 2324,   11]),\n",
       " tensor([ 813, 2324,   11, 1047]),\n",
       " tensor([2324,   11, 1047, 1027]),\n",
       " tensor([   11,  1047,  1027, 23712]),\n",
       " tensor([ 1047,  1027, 23712,   555]),\n",
       " tensor([ 1027, 23712,   555,  7185]),\n",
       " tensor([23712,   555,  7185,  3278]),\n",
       " tensor([ 555, 7185, 3278,   25]),\n",
       " tensor([7185, 3278,   25,  814]),\n",
       " tensor([3278,   25,  814, 1047]),\n",
       " tensor([   25,   814,  1047, 31087]),\n",
       " tensor([  814,  1047, 31087,   291]),\n",
       " tensor([ 1047, 31087,   291,   813]),\n",
       " tensor([31087,   291,   813,  1989]),\n",
       " tensor([ 291,  813, 1989,   11]),\n",
       " tensor([ 813, 1989,   11,  433]),\n",
       " tensor([1989,   11,  433, 1047]),\n",
       " tensor([  11,  433, 1047, 1027]),\n",
       " tensor([ 433, 1047, 1027,  312]),\n",
       " tensor([1047, 1027,  312, 1636]),\n",
       " tensor([1027,  312, 1636,  304]),\n",
       " tensor([ 312, 1636,  304,  279]),\n",
       " tensor([1636,  304,  279, 4106]),\n",
       " tensor([  304,   279,  4106, 37002]),\n",
       " tensor([  279,  4106, 37002,   315]),\n",
       " tensor([ 4106, 37002,   315,   872]),\n",
       " tensor([37002,   315,   872,  1008]),\n",
       " tensor([ 315,  872, 1008, 2987]),\n",
       " tensor([ 872, 1008, 2987,   13]),\n",
       " tensor([1008, 2987,   13, 1628]),\n",
       " tensor([2987,   13, 1628,  433]),\n",
       " tensor([  13, 1628,  433,  574]),\n",
       " tensor([1628,  433,  574, 9093]),\n",
       " tensor([  433,   574,  9093, 21745]),\n",
       " tensor([  574,  9093, 21745,   535]),\n",
       " tensor([ 9093, 21745,   535,   311]),\n",
       " tensor([21745,   535,   311,  5296]),\n",
       " tensor([ 535,  311, 5296, 1148]),\n",
       " tensor([ 311, 5296, 1148, 2515]),\n",
       " tensor([5296, 1148, 2515,  279]),\n",
       " tensor([1148, 2515,  279,  330]),\n",
       " tensor([ 2515,   279,   330, 34854]),\n",
       " tensor([  279,   330, 34854,  6147]),\n",
       " tensor([  330, 34854,  6147, 16975]),\n",
       " tensor([34854,  6147, 16975,   315]),\n",
       " tensor([ 6147, 16975,   315, 25098]),\n",
       " tensor([16975,   315, 25098,  4309]),\n",
       " tensor([  315, 25098,  4309,   488]),\n",
       " tensor([25098,  4309,   488,     1]),\n",
       " tensor([4309,  488,    1,  320]),\n",
       " tensor([488,   1, 320,  40]),\n",
       " tensor([    1,   320,    40, 12929]),\n",
       " tensor([  320,    40, 12929,  9083]),\n",
       " tensor([   40, 12929,  9083, 25611]),\n",
       " tensor([12929,  9083, 25611,   728]),\n",
       " tensor([ 9083, 25611,   728,     8]),\n",
       " tensor([25611,   728,     8,   574]),\n",
       " tensor([ 728,    8,  574, 3515]),\n",
       " tensor([   8,  574, 3515,  389]),\n",
       " tensor([ 574, 3515,  389, 1461]),\n",
       " tensor([3515,  389, 1461,  382]),\n",
       " tensor([ 389, 1461,  382,   40]),\n",
       " tensor([1461,  382,   40,  617]),\n",
       " tensor([ 382,   40,  617, 9932]),\n",
       " tensor([  40,  617, 9932,  430]),\n",
       " tensor([  617,  9932,   430, 18083]),\n",
       " tensor([ 9932,   430, 18083,    13]),\n",
       " tensor([  430, 18083,    13,   480]),\n",
       " tensor([18083,    13,   480,   285]),\n",
       " tensor([   13,   480,   285, 22464]),\n",
       " tensor([  480,   285, 22464,   574]),\n",
       " tensor([  285, 22464,   574,  9257]),\n",
       " tensor([22464,   574,  9257,    26]),\n",
       " tensor([ 574, 9257,   26,  323]),\n",
       " tensor([9257,   26,  323,  433]),\n",
       " tensor([ 26, 323, 433, 574]),\n",
       " tensor([ 323,  433,  574, 7214]),\n",
       " tensor([  433,   574,  7214, 78632]),\n",
       " tensor([  574,  7214, 78632,  1260]),\n",
       " tensor([ 7214, 78632,  1260,   430]),\n",
       " tensor([78632,  1260,   430,  1077]),\n",
       " tensor([ 1260,   430,  1077, 10177]),\n",
       " tensor([  430,  1077, 10177,   574]),\n",
       " tensor([ 1077, 10177,   574, 60508]),\n",
       " tensor([10177,   574, 60508,   505]),\n",
       " tensor([  574, 60508,   505,   420]),\n",
       " tensor([60508,   505,   420, 53237]),\n",
       " tensor([  505,   420, 53237,   264]),\n",
       " tensor([  420, 53237,   264, 36301]),\n",
       " tensor([53237,   264, 36301,   719]),\n",
       " tensor([  264, 36301,   719, 12190]),\n",
       " tensor([36301,   719, 12190, 24617]),\n",
       " tensor([  719, 12190, 24617,    13]),\n",
       " tensor([12190, 24617,    13,  1102]),\n",
       " tensor([24617,    13,  1102,   374]),\n",
       " tensor([  13, 1102,  374,   11]),\n",
       " tensor([1102,  374,   11,  439]),\n",
       " tensor([374,  11, 439, 264]),\n",
       " tensor([  11,  439,  264, 6037]),\n",
       " tensor([ 439,  264, 6037,   11]),\n",
       " tensor([ 264, 6037,   11,  279]),\n",
       " tensor([6037,   11,  279, 1274]),\n",
       " tensor([  11,  279, 1274,  889]),\n",
       " tensor([  279,  1274,   889, 88106]),\n",
       " tensor([ 1274,   889, 88106,  3300]),\n",
       " tensor([  889, 88106,  3300,   889]),\n",
       " tensor([88106,  3300,   889,   636]),\n",
       " tensor([3300,  889,  636, 1455]),\n",
       " tensor([ 889,  636, 1455,  704]),\n",
       " tensor([ 636, 1455,  704,  315]),\n",
       " tensor([1455,  704,  315,  433]),\n",
       " tensor([704, 315, 433,  26]),\n",
       " tensor([315, 433,  26, 323]),\n",
       " tensor([ 433,   26,  323, 7762]),\n",
       " tensor([  26,  323, 7762,  596]),\n",
       " tensor([  323,  7762,   596, 26861]),\n",
       " tensor([ 7762,   596, 26861, 79498]),\n",
       " tensor([  596, 26861, 79498,   315]),\n",
       " tensor([26861, 79498,   315,   813]),\n",
       " tensor([79498,   315,   813,  7555]),\n",
       " tensor([ 315,  813, 7555,  596]),\n",
       " tensor([ 813, 7555,  596, 2466]),\n",
       " tensor([7555,  596, 2466, 8335]),\n",
       " tensor([ 596, 2466, 8335, 9147]),\n",
       " tensor([2466, 8335, 9147, 1461]),\n",
       " tensor([8335, 9147, 1461,   11]),\n",
       " tensor([9147, 1461,   11,  449]),\n",
       " tensor([1461,   11,  449,  459]),\n",
       " tensor([   11,   449,   459, 11341]),\n",
       " tensor([  449,   459, 11341,   315]),\n",
       " tensor([  459, 11341,   315,  4832]),\n",
       " tensor([11341,   315,  4832,  1695]),\n",
       " tensor([  315,  4832,  1695, 93008]),\n",
       " tensor([ 4832,  1695, 93008, 16490]),\n",
       " tensor([ 1695, 93008, 16490,    11]),\n",
       " tensor([93008, 16490,    11,   311]),\n",
       " tensor([16490,    11,   311,  1380]),\n",
       " tensor([   11,   311,  1380, 53314]),\n",
       " tensor([  311,  1380, 53314,   433]),\n",
       " tensor([ 1380, 53314,   433,  1139]),\n",
       " tensor([53314,   433,  1139,  6302]),\n",
       " tensor([ 433, 1139, 6302,  315]),\n",
       " tensor([1139, 6302,  315, 1989]),\n",
       " tensor([6302,  315, 1989,  323]),\n",
       " tensor([  315,  1989,   323, 19913]),\n",
       " tensor([ 1989,   323, 19913,    13]),\n",
       " tensor([  323, 19913,    13,  2057]),\n",
       " tensor([19913,    13,  2057,   279]),\n",
       " tensor([   13,  2057,   279, 15629]),\n",
       " tensor([ 2057,   279, 15629,    11]),\n",
       " tensor([  279, 15629,    11,   358]),\n",
       " tensor([15629,    11,   358,  2011]),\n",
       " tensor([  11,  358, 2011,  923]),\n",
       " tensor([ 358, 2011,  923,   11]),\n",
       " tensor([2011,  923,   11,  568]),\n",
       " tensor([  923,    11,   568, 14958]),\n",
       " tensor([   11,   568, 14958, 12309]),\n",
       " tensor([  568, 14958, 12309, 80008]),\n",
       " tensor([14958, 12309, 80008,    26]),\n",
       " tensor([12309, 80008,    26,   719]),\n",
       " tensor([80008,    26,   719,   568]),\n",
       " tensor([ 26, 719, 568, 574]),\n",
       " tensor([  719,   568,   574, 12096]),\n",
       " tensor([  568,   574, 12096, 55383]),\n",
       " tensor([  574, 12096, 55383,  1437]),\n",
       " tensor([12096, 55383,  1437, 28143]),\n",
       " tensor([55383,  1437, 28143,   288]),\n",
       " tensor([ 1437, 28143,   288,   323]),\n",
       " tensor([28143,   288,   323,  8223]),\n",
       " tensor([  288,   323,  8223, 62655]),\n",
       " tensor([  323,  8223, 62655, 34457]),\n",
       " tensor([ 8223, 62655, 34457,  9364]),\n",
       " tensor([62655, 34457,  9364,   449]),\n",
       " tensor([34457,  9364,   449,   264]),\n",
       " tensor([ 9364,   449,   264, 21934]),\n",
       " tensor([  449,   264, 21934,   430]),\n",
       " tensor([  264, 21934,   430, 76649]),\n",
       " tensor([21934,   430, 76649,   279]),\n",
       " tensor([  430, 76649,   279, 42853]),\n",
       " tensor([76649,   279, 42853,   267]),\n",
       " tensor([  279, 42853,   267,  5070]),\n",
       " tensor([42853,   267,  5070,   382]),\n",
       " tensor([ 267, 5070,  382,    1]),\n",
       " tensor([ 5070,   382,     1, 25821]),\n",
       " tensor([  382,     1, 25821,   596]),\n",
       " tensor([    1, 25821,   596,  1193]),\n",
       " tensor([25821,   596,  1193, 28391]),\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetv1.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e485e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2744, 3463, 7762,  480]), tensor([3463, 7762,  480,  285]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetv1.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb6b2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride) \n",
    "    dataloader = DataLoader(\n",
    "                            dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last, \n",
    "                            num_workers=num_workers \n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "add16a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d069a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d53e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  473, 1846, 2744]]), tensor([[ 473, 1846, 2744, 3463]])]\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b803cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 473, 1846, 2744, 3463]]), tensor([[1846, 2744, 3463, 7762]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c9ee13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader2 = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3830d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[   40,   473,  1846,  2744],\n",
      "        [ 3463,  7762,   480,   285],\n",
      "        [22464,  4856,   264, 12136],\n",
      "        [35201,   313,  4636,   264],\n",
      "        [ 1695, 12637,  3403,   313],\n",
      "        [  708,   433,   574,   912],\n",
      "        [ 2294, 13051,   311,   757],\n",
      "        [  311,  6865,   430,    11]])\n",
      "target:  tensor([[  473,  1846,  2744,  3463],\n",
      "        [ 7762,   480,   285, 22464],\n",
      "        [ 4856,   264, 12136, 35201],\n",
      "        [  313,  4636,   264,  1695],\n",
      "        [12637,  3403,   313,   708],\n",
      "        [  433,   574,   912,  2294],\n",
      "        [13051,   311,   757,   311],\n",
      "        [ 6865,   430,    11,   304]])\n"
     ]
    }
   ],
   "source": [
    "data_iter2 = iter(dataloader2)\n",
    "inputs, targets = next(data_iter2)\n",
    "print(\"input: \", inputs)\n",
    "print(\"target: \", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b3940f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[  304,   279,  2673,   315],\n",
      "        [  813, 27025,    11,   568],\n",
      "        [ 1047, 12504,   813, 19354],\n",
      "        [   11, 12502,   264,  9257],\n",
      "        [57896,    11,   323,  9749],\n",
      "        [ 5678,   304,   264, 47625],\n",
      "        [  389,   279, 51768, 26919],\n",
      "        [   13,   320, 27831,   358]])\n",
      "target:  tensor([[  279,  2673,   315,   813],\n",
      "        [27025,    11,   568,  1047],\n",
      "        [12504,   813, 19354,    11],\n",
      "        [12502,   264,  9257, 57896],\n",
      "        [   11,   323,  9749,  5678],\n",
      "        [  304,   264, 47625,   389],\n",
      "        [  279, 51768, 26919,    13],\n",
      "        [  320, 27831,   358,  4856]])\n"
     ]
    }
   ],
   "source": [
    "inputs2, targets2 = next(data_iter2)\n",
    "print(\"input: \", inputs2)\n",
    "print(\"target: \", targets2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c26b8",
   "metadata": {},
   "source": [
    "### 2.7 Creating token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8133c1",
   "metadata": {},
   "source": [
    "将token id进行向量嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7449894",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71c79841",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca697eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ebf9608d70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81c919c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "635d21b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd383fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 对单个token id进行向量嵌入\n",
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b94b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 对多个token id进行向量嵌入\n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ace2e",
   "metadata": {},
   "source": [
    "### 2.8 Encoding word positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6959297",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f975db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建嵌入层，vocab_size表示一次处理几个值，output_dim表示每个值变为几维向量\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1379a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文字数据变为token id\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4c51743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[   40,   473,  1846,  2744],\n",
      "        [ 3463,  7762,   480,   285],\n",
      "        [22464,  4856,   264, 12136],\n",
      "        [35201,   313,  4636,   264],\n",
      "        [ 1695, 12637,  3403,   313],\n",
      "        [  708,   433,   574,   912],\n",
      "        [ 2294, 13051,   311,   757],\n",
      "        [  311,  6865,   430,    11]])\n",
      "target:  tensor([[  473,  1846,  2744,  3463],\n",
      "        [ 7762,   480,   285, 22464],\n",
      "        [ 4856,   264, 12136, 35201],\n",
      "        [  313,  4636,   264,  1695],\n",
      "        [12637,  3403,   313,   708],\n",
      "        [  433,   574,   912,  2294],\n",
      "        [13051,   311,   757,   311],\n",
      "        [ 6865,   430,    11,   304]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "input_ids, target_ids = next(dataiter)\n",
    "print(\"input: \", input_ids)\n",
    "print(\"target: \", target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88dd5164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4913,  1.1239,  1.4588,  ..., -0.3995, -1.8735, -0.1445],\n",
      "         [-0.8191,  0.2605,  0.5637,  ..., -1.4546,  1.7735, -0.5172],\n",
      "         [-0.1778, -1.1731, -1.8769,  ...,  0.1934, -0.7914, -1.6395],\n",
      "         [ 1.0257, -0.8298, -0.8972,  ..., -0.0812, -0.5273,  0.0268]],\n",
      "\n",
      "        [[ 0.3395, -0.2356,  1.8618,  ...,  0.0056, -0.8215, -1.5837],\n",
      "         [-1.4556,  0.4396,  1.2542,  ...,  0.4209,  1.2177,  0.3914],\n",
      "         [ 1.1792, -1.0156, -0.1078,  ..., -0.2914, -0.7526, -0.8195],\n",
      "         [ 0.7219,  0.5423, -0.7337,  ...,  0.1182, -0.4828, -0.2856]],\n",
      "\n",
      "        [[-0.6609,  1.0887, -0.0345,  ...,  2.1770, -0.0629, -1.1514],\n",
      "         [ 1.2575, -0.9567, -1.2624,  ..., -0.5898, -0.7390,  0.6355],\n",
      "         [-0.2603,  0.8579,  0.9012,  ..., -1.5838,  1.0285,  0.8128],\n",
      "         [-0.7562, -1.2479,  0.2260,  ...,  1.3723,  0.3643,  0.6230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4008,  0.4796, -0.1928,  ..., -1.0423,  0.7868,  0.0060],\n",
      "         [-0.4998, -0.3685, -0.3767,  ..., -1.2173,  2.5697,  1.7124],\n",
      "         [-1.0211,  0.1372,  1.3368,  ...,  1.1086,  0.5233, -2.2873],\n",
      "         [ 1.3549, -1.5243, -0.8214,  ..., -0.8195,  1.4819, -0.1798]],\n",
      "\n",
      "        [[ 0.0255, -0.1062,  0.9961,  ...,  0.5080, -1.7533, -1.8805],\n",
      "         [-1.1474, -1.8864, -0.2725,  ...,  0.6471,  0.1789,  1.6177],\n",
      "         [ 2.3078,  1.3747,  1.2231,  ..., -0.7627, -0.6905,  0.8710],\n",
      "         [-1.5409, -0.0810, -0.1245,  ..., -0.7529,  1.6298, -1.0356]],\n",
      "\n",
      "        [[ 2.3078,  1.3747,  1.2231,  ..., -0.7627, -0.6905,  0.8710],\n",
      "         [-0.1153,  0.4590,  1.1684,  ..., -0.4836,  1.8473, -0.0890],\n",
      "         [ 1.5131,  0.0478, -0.4348,  ..., -0.4118, -0.2281, -0.0322],\n",
      "         [ 1.1274, -0.1082, -0.2195,  ...,  0.5059, -1.8138, -0.0700]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 对每个token id进行向量嵌入，此时每个token id变为256维\n",
    "token_vector = token_embedding_layer(input_ids)\n",
    "print(token_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f96aa7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b8e6d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1265, -0.0513,  1.3903,  ...,  0.7732, -0.0831,  0.0133],\n",
      "        [ 1.8435, -0.4803, -0.6885,  ..., -1.9100, -0.1373,  1.5089],\n",
      "        [-0.8424,  0.2939, -0.5960,  ...,  1.3296,  0.1291,  0.5257],\n",
      "        [ 0.0491, -1.4016,  0.1980,  ..., -0.4796, -1.4831, -0.8476]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 考虑相对位置，使用递增序列建立嵌入向量，并分与token id变为的嵌入向量进行加和，由于广播机制，位置向量会分别和每一行token id变为的向量加和\n",
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embedding = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acece667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(pos_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d535f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 6.1783e-01,  1.0725e+00,  2.8492e+00,  ...,  3.7365e-01,\n",
      "          -1.9567e+00, -1.3124e-01],\n",
      "         [ 1.0244e+00, -2.1971e-01, -1.2481e-01,  ..., -3.3645e+00,\n",
      "           1.6362e+00,  9.9172e-01],\n",
      "         [-1.0203e+00, -8.7917e-01, -2.4728e+00,  ...,  1.5230e+00,\n",
      "          -6.6232e-01, -1.1139e+00],\n",
      "         [ 1.0748e+00, -2.2315e+00, -6.9911e-01,  ..., -5.6082e-01,\n",
      "          -2.0104e+00, -8.2086e-01]],\n",
      "\n",
      "        [[ 4.6606e-01, -2.8699e-01,  3.2521e+00,  ...,  7.7877e-01,\n",
      "          -9.0464e-01, -1.5704e+00],\n",
      "         [ 3.8791e-01, -4.0674e-02,  5.6573e-01,  ..., -1.4891e+00,\n",
      "           1.0804e+00,  1.9002e+00],\n",
      "         [ 3.3682e-01, -7.2166e-01, -7.0378e-01,  ...,  1.0382e+00,\n",
      "          -6.2352e-01, -2.9384e-01],\n",
      "         [ 7.7102e-01, -8.5930e-01, -5.3568e-01,  ..., -3.6143e-01,\n",
      "          -1.9659e+00, -1.1332e+00]],\n",
      "\n",
      "        [[-5.3433e-01,  1.0373e+00,  1.3558e+00,  ...,  2.9502e+00,\n",
      "          -1.4602e-01, -1.1380e+00],\n",
      "         [ 3.1010e+00, -1.4369e+00, -1.9509e+00,  ..., -2.4998e+00,\n",
      "          -8.7628e-01,  2.1444e+00],\n",
      "         [-1.1027e+00,  1.1518e+00,  3.0524e-01,  ..., -2.5427e-01,\n",
      "           1.1576e+00,  1.3385e+00],\n",
      "         [-7.0706e-01, -2.6496e+00,  4.2405e-01,  ...,  8.9263e-01,\n",
      "          -1.1188e+00, -2.2464e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.2738e-01,  4.2830e-01,  1.1975e+00,  ..., -2.6907e-01,\n",
      "           7.0368e-01,  1.9319e-02],\n",
      "         [ 1.3438e+00, -8.4878e-01, -1.0652e+00,  ..., -3.1273e+00,\n",
      "           2.4325e+00,  3.2213e+00],\n",
      "         [-1.8636e+00,  4.3110e-01,  7.4085e-01,  ...,  2.4382e+00,\n",
      "           6.5241e-01, -1.7616e+00],\n",
      "         [ 1.4040e+00, -2.9259e+00, -6.2338e-01,  ..., -1.2991e+00,\n",
      "          -1.2099e-03, -1.0274e+00]],\n",
      "\n",
      "        [[ 1.5201e-01, -1.5756e-01,  2.3864e+00,  ...,  1.2812e+00,\n",
      "          -1.8364e+00, -1.8672e+00],\n",
      "         [ 6.9612e-01, -2.3666e+00, -9.6103e-01,  ..., -1.2629e+00,\n",
      "           4.1631e-02,  3.1266e+00],\n",
      "         [ 1.4653e+00,  1.6686e+00,  6.2717e-01,  ...,  5.6684e-01,\n",
      "          -5.6143e-01,  1.3966e+00],\n",
      "         [-1.4918e+00, -1.4826e+00,  7.3591e-02,  ..., -1.2325e+00,\n",
      "           1.4672e-01, -1.8832e+00]],\n",
      "\n",
      "        [[ 2.4343e+00,  1.3233e+00,  2.6134e+00,  ...,  1.0462e-02,\n",
      "          -7.7365e-01,  8.8428e-01],\n",
      "         [ 1.7283e+00, -2.1291e-02,  4.7991e-01,  ..., -2.3935e+00,\n",
      "           1.7100e+00,  1.4199e+00],\n",
      "         [ 6.7063e-01,  3.4172e-01, -1.0308e+00,  ...,  9.1774e-01,\n",
      "          -9.8984e-02,  4.9350e-01],\n",
      "         [ 1.1765e+00, -1.5099e+00, -2.1497e-02,  ...,  2.6269e-02,\n",
      "          -3.2969e+00, -9.1761e-01]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_vector + pos_embedding\n",
    "print(input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49c56806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
